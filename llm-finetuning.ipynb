{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Language Model (LLM) Finetuning\n",
    "\n",
    "This notebook contains code to evaluate an LLM on a subset of the [SQuAD dataset](https://huggingface.co/datasets/rajpurkar/squad) (Stanford Question Answering Dataset), fine-tune it on it and reevaluate to check model's performance. Along the way, we'll stop and explain several of the concepts involved across similar tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "The problem at hand is a subfield of Natural Language Processing (NLP) called Question Answering (QA). The goal is to, asking an LLM a question given some context, receive an appropriate answer included in the beforementioned context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizerFast, Trainer, TrainingArguments, pipeline\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "Nowadays, LLMs are versatile enough to address this and many other problems through prompt engineering. Within this framework, engineers tweak their prompts in order to get the best possible results to their problems. However, generalist LLMs can become unfeasible to use depending on computational, budget and response time constraints. This is why, depending on the problem at hand, a more direct approach might be better fitting.  \n",
    "One personally recommended course of action is to first check the available models that aims to solve the problem of interest. The HuggingFace (HF) Hub is a well known initiative where to check many resources, including models and datasets. This way, it's easy to check the best models for a particular task.  \n",
    "Besides model comparison regarding purely evaluation metrics, other very important aspect of LLM deployment is its size. Many of them are traditionally large enough to prove themselves challenging to host. A useful tool might be the [Can you run it? LLM version](https://huggingface.co/spaces/Vokturz/can-it-run-llm) from HF. It allows the user to select a model, hardware, and the web will display if it's feasible or not to run it on 1 or more GPUs depending on quantization, training adequacy, etc.  \n",
    "For this particular project, which is meant to showcase how to perform fine-tuning and evaluations in a normal setup rather than finding the best possible solution, we'll start from [DistilBERT base model](https://huggingface.co/distilbert/distilbert-base-uncased) rather than already fine-tuned ones in the desired Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The Dataset of interest is the Stanford Question Answering Dataset ([SQuAD](https://huggingface.co/datasets/rajpurkar/squad)). It comprehends a set of segments of text from Wikipedia (context) alongside questions and answers that can be found in the given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing\n",
    "\n",
    "Usually, Deep Learning (FL) applications require some preprocessing to their inputs. In NLP, this may involve some text cleaning, tokenization (technique that depends on the model of choice), truncation handling, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, \n",
    "                            remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "\n",
    "Training an LLM from scratch can be very slow and costly. Instead, one common practice in DL is to start from an already pre-trained model and start training from there (what we call fine-tuning). The code below shows the training configuration through HF: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xavia\\Projects\\llm-finetuning\\venv\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,\n",
    "    report_to=\"tensorboard\", \n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right after it, it's possible to evaluate the initial model against the SQuAD's *validation* subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 661/661 [00:28<00:00, 22.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.8978590965271,\n",
       " 'eval_model_preparation_time': 0.001,\n",
       " 'eval_runtime': 29.405,\n",
       " 'eval_samples_per_second': 359.462,\n",
       " 'eval_steps_per_second': 22.479}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting a baseline, let's start the QA model's fine-tuning.  \n",
    "**Note:** This step can take a significant amount of time depending on hardware specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training will create some output logs that can be read with TensorBoard. You can start TensorBoard with the following command:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir logs/\n",
    "```\n",
    "\n",
    "TensorBoard provides useful information in a visual way. For example, monitoring the train and eval losses while training can give information about the current's training state. For instance, if both losses are high and do not decrease over time, the model may be underfitting. On the other hand, if the train loss decreases but the eval one starts to increase, it might be overfitting. Depending on the scenario, the engineer might choose to look for more powerful architectures, more broad and representative data, or start with hyperparameter (HP) tuning. The most common one to tweak is the Learning Rate (LR): one too big might yield to quick improvements at the risk of reaching a loss plateau. On the other hand, a smaller one might make the training too slow. It's recommended to play with HP for the optimizers (e.g. Adam) or different strategies to get the best possible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a model has already been fine-tuned, specify the checkpoint of your choice below to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = \"./results/checkpoint-10000\"\n",
    "\n",
    "finetuned_model = DistilBertForQuestionAnswering.from_pretrained(best_checkpoint)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation comparison\n",
    "\n",
    "After having available both models, the pre-trained and the fine-tuned ones, let's make a more thorough evaluation comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 661/661 [00:29<00:00, 22.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.956923484802246,\n",
       " 'eval_model_preparation_time': 0.001,\n",
       " 'eval_runtime': 29.3675,\n",
       " 'eval_samples_per_second': 359.922,\n",
       " 'eval_steps_per_second': 22.508}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 661/661 [00:29<00:00, 22.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1106374263763428,\n",
       " 'eval_model_preparation_time': 0.001,\n",
       " 'eval_runtime': 29.3136,\n",
       " 'eval_samples_per_second': 360.584,\n",
       " 'eval_steps_per_second': 22.549}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tuned model evaluation\n",
    "trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"validation\"],\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation loss difference (lower is better) already shows that the fine-tuned model is better than the baseline.  \n",
    "Furthermore, it's possible to make a more thorough analysis by generating the model's responses and performing an Error Analysis (EA). For that purpose, let's use the HF's *question answering pipeline*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "qa_pipeline = pipeline(\"question-answering\", \n",
    "                       model=\"distilbert-base-uncased\", \n",
    "                       tokenizer=tokenizer, \n",
    "                       batch_size=64)\n",
    "\n",
    "finetuned_qa_pipeline = pipeline(\"question-answering\", \n",
    "                                 model=finetuned_model, \n",
    "                                 tokenizer=tokenizer,\n",
    "                                 batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's reuse the SQuAD's validation dataset to store the predicted answers and scores for both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(example):\n",
    "    baseline_prediction = qa_pipeline(question=example[\"question\"], context=example[\"context\"])\n",
    "    finetuned_prediction = finetuned_qa_pipeline(question=example[\"question\"], context=example[\"context\"])\n",
    "    return {\n",
    "        \"baseline_prediction\": baseline_prediction[\"answer\"],\n",
    "        \"baseline_score\": baseline_prediction[\"score\"],\n",
    "        \"finetuned_prediction\": finetuned_prediction[\"answer\"],\n",
    "        \"finetuned_score\": finetuned_prediction[\"score\"],\n",
    "        \"ground_truth\": example[\"answers\"][\"text\"][0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10570/10570 [13:55<00:00, 12.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = squad[\"validation\"].map(get_prediction, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data at hand, let's use the *HF's evaluate* library to check more evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SQuAD metric is expecting a list of dictionaries containing:\n",
    "* **id:** ID of the sample.\n",
    "* **answers:** Predicted answer or list of ground truth answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_predicted_answers = [{\"id\": pred[\"id\"],\n",
    "                               \"prediction_text\": pred[\"baseline_prediction\"]}\n",
    "                               for pred in predictions]\n",
    "finetuned_predicted_answers = [{\"id\": pred[\"id\"],\n",
    "                                \"prediction_text\": pred[\"finetuned_prediction\"]}\n",
    "                                for pred in predictions]\n",
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in predictions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.8609271523178808, 'f1': 7.889010128219963}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model's evaluation metrics\n",
    "metric.compute(predictions=baseline_predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 76.59413434247871, 'f1': 84.8074232750765}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tuned model's evaluation metrics\n",
    "metric.compute(predictions=finetuned_predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it's even more clear that the fine-tuned model is way superior than the baseline. The exact matches indicates the cases where the predictions matched precisely the ground truth answer.  \n",
    "On the other hand, the F1-score is the harmonic mean of the Precision and the Recall, which can be calculated with:\n",
    "* True Positive: Number of shared tokens between the prediction and the correct answer.\n",
    "* False Positive: Number of tokens in the predicted sequence, excluding the shared tokens.\n",
    "* False Negative: Number of tokens in the correct answer, excluding the shared tokens.  \n",
    "In case more specific, sample level metrics are required, it's possible to write custom functions. One possible addition is the Levenshtein distance, which measures the amount of changes needed in one string to become a reference one (less is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_match(prediction, ground_truth):\n",
    "    return int(prediction == ground_truth)\n",
    "\n",
    "def compute_f1(prediction, ground_truth):\n",
    "    pred_tokens = prediction.split()\n",
    "    gt_tokens = ground_truth.split()\n",
    "    common_tokens = set(pred_tokens) & set(gt_tokens)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0.0\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(gt_tokens)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(prediction):\n",
    "    baseline_exact_match = compute_exact_match(prediction[\"baseline_prediction\"], prediction[\"answers\"][\"text\"][0])\n",
    "    baseline_f1 = compute_f1(prediction[\"baseline_prediction\"], prediction[\"answers\"][\"text\"][0])\n",
    "    baseline_lev = Levenshtein.distance(prediction[\"baseline_prediction\"], prediction[\"answers\"][\"text\"][0])\n",
    "    finetuned_exact_match = compute_exact_match(prediction[\"finetuned_prediction\"], prediction[\"answers\"][\"text\"][0])\n",
    "    finetuned_f1 = compute_f1(prediction[\"finetuned_prediction\"], prediction[\"answers\"][\"text\"][0])\n",
    "    finetuned_lev = Levenshtein.distance(prediction[\"finetuned_prediction\"], prediction[\"answers\"][\"text\"][0])\n",
    "    return {\n",
    "        \"baseline_exact_match\": baseline_exact_match,\n",
    "        \"baseline_f1\": baseline_f1, \n",
    "        \"baseline_lev\": baseline_lev, \n",
    "        \"finetuned_exact_match\": finetuned_exact_match, \n",
    "        \"finetuned_f1\": finetuned_f1, \n",
    "        \"finetuned_lev\": finetuned_lev, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10570/10570 [00:00<00:00, 12477.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_with_metrics = predictions.map(get_eval_metrics, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Save the new dataset with all predictions and metrics to avoid recalculating everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10570/10570 [00:00<00:00, 704605.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_with_metrics.save_to_disk(\"./predictions_with_metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by converting the *HF dataset* into pandas, we gain more control about the data and how to analyze it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions_with_metrics.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_score</th>\n",
       "      <th>finetuned_score</th>\n",
       "      <th>baseline_exact_match</th>\n",
       "      <th>baseline_f1</th>\n",
       "      <th>baseline_lev</th>\n",
       "      <th>finetuned_exact_match</th>\n",
       "      <th>finetuned_f1</th>\n",
       "      <th>finetuned_lev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10570.000000</td>\n",
       "      <td>10570.000000</td>\n",
       "      <td>10570.0</td>\n",
       "      <td>10570.000000</td>\n",
       "      <td>10570.000000</td>\n",
       "      <td>10570.000000</td>\n",
       "      <td>10570.000000</td>\n",
       "      <td>10570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.572211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043122</td>\n",
       "      <td>39.037370</td>\n",
       "      <td>0.571239</td>\n",
       "      <td>0.747881</td>\n",
       "      <td>8.341343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.293062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113308</td>\n",
       "      <td>19.240878</td>\n",
       "      <td>0.494922</td>\n",
       "      <td>0.360389</td>\n",
       "      <td>16.390617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.325124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.578012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.849143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baseline_score  finetuned_score  baseline_exact_match   baseline_f1  \\\n",
       "count    10570.000000     10570.000000               10570.0  10570.000000   \n",
       "mean         0.000162         0.572211                   0.0      0.043122   \n",
       "std          0.000219         0.293062                   0.0      0.113308   \n",
       "min          0.000018         0.006408                   0.0      0.000000   \n",
       "25%          0.000070         0.325124                   0.0      0.000000   \n",
       "50%          0.000112         0.578012                   0.0      0.000000   \n",
       "75%          0.000172         0.849143                   0.0      0.000000   \n",
       "max          0.002750         0.999911                   0.0      0.923077   \n",
       "\n",
       "       baseline_lev  finetuned_exact_match  finetuned_f1  finetuned_lev  \n",
       "count  10570.000000           10570.000000  10570.000000   10570.000000  \n",
       "mean      39.037370               0.571239      0.747881       8.341343  \n",
       "std       19.240878               0.494922      0.360389      16.390617  \n",
       "min        1.000000               0.000000      0.000000       0.000000  \n",
       "25%       24.000000               0.000000      0.571429       0.000000  \n",
       "50%       37.000000               1.000000      1.000000       0.000000  \n",
       "75%       52.000000               1.000000      1.000000      10.000000  \n",
       "max      145.000000               1.000000      1.000000     152.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>baseline_prediction</th>\n",
       "      <th>finetuned_prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>baseline_score</th>\n",
       "      <th>finetuned_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>Economic_inequality</td>\n",
       "      <td>What nationality are researchers Richard G. Wi...</td>\n",
       "      <td>British researchers Richard G. Wilkinson and K...</td>\n",
       "      <td>conflict, drug use), and lower rates of social...</td>\n",
       "      <td>British</td>\n",
       "      <td>British</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.999911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>Economic_inequality</td>\n",
       "      <td>What career does Joseph Stiglitz have?</td>\n",
       "      <td>Economist Joseph Stiglitz argues that rather t...</td>\n",
       "      <td>., it will also prevent</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.999878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Imperialism</td>\n",
       "      <td>What was the capital of the Ottoman empire?</td>\n",
       "      <td>With Istanbul as its capital and control of la...</td>\n",
       "      <td>, thus</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>Economic_inequality</td>\n",
       "      <td>What profession does Simon Kuznets have?</td>\n",
       "      <td>Economist Simon Kuznets argued that levels of ...</td>\n",
       "      <td>. According to Kuznets, countries with low lev...</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.999874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>Apollo_program</td>\n",
       "      <td>In what year did the Apollo 1 cabin fire occur?</td>\n",
       "      <td>The Apollo program succeeded in achieving its ...</td>\n",
       "      <td>. Budget cuts forced the cancellation of three...</td>\n",
       "      <td>1967</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.999668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509</th>\n",
       "      <td>Economic_inequality</td>\n",
       "      <td>What year did Robert J. Shiller win an Economi...</td>\n",
       "      <td>2013 Economics Nobel prize winner Robert J. Sh...</td>\n",
       "      <td>, and erodes</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.999642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>Victoria_(Australia)</td>\n",
       "      <td>What state in Australia is the center of dairy...</td>\n",
       "      <td>Victoria is the centre of dairy farming in Aus...</td>\n",
       "      <td>. In 2003â€“04, Victorian commercial fishing cre...</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.999574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5683</th>\n",
       "      <td>Victoria_and_Albert_Museum</td>\n",
       "      <td>In which year was the The Forest tapestry crea...</td>\n",
       "      <td>One of the earliest surviving examples of Euro...</td>\n",
       "      <td>, as well as pattern books and paper</td>\n",
       "      <td>1887</td>\n",
       "      <td>1887</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.999562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>Fresno,_California</td>\n",
       "      <td>Which is the largest city not connected to an ...</td>\n",
       "      <td>Fresno is the largest U.S. city not directly l...</td>\n",
       "      <td>, much discussion has been made to upgrade it ...</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.999516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7577</th>\n",
       "      <td>Economic_inequality</td>\n",
       "      <td>What's Thomas Piketty's job?</td>\n",
       "      <td>Studies on income inequality and growth have s...</td>\n",
       "      <td>, which states that with economic development,...</td>\n",
       "      <td>Economist</td>\n",
       "      <td>Economist</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.999464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "7514         Economic_inequality   \n",
       "7500         Economic_inequality   \n",
       "9997                 Imperialism   \n",
       "7476         Economic_inequality   \n",
       "3830              Apollo_program   \n",
       "7509         Economic_inequality   \n",
       "3002        Victoria_(Australia)   \n",
       "5683  Victoria_and_Albert_Museum   \n",
       "4798          Fresno,_California   \n",
       "7577         Economic_inequality   \n",
       "\n",
       "                                               question  \\\n",
       "7514  What nationality are researchers Richard G. Wi...   \n",
       "7500             What career does Joseph Stiglitz have?   \n",
       "9997        What was the capital of the Ottoman empire?   \n",
       "7476           What profession does Simon Kuznets have?   \n",
       "3830    In what year did the Apollo 1 cabin fire occur?   \n",
       "7509  What year did Robert J. Shiller win an Economi...   \n",
       "3002  What state in Australia is the center of dairy...   \n",
       "5683  In which year was the The Forest tapestry crea...   \n",
       "4798  Which is the largest city not connected to an ...   \n",
       "7577                       What's Thomas Piketty's job?   \n",
       "\n",
       "                                                context  \\\n",
       "7514  British researchers Richard G. Wilkinson and K...   \n",
       "7500  Economist Joseph Stiglitz argues that rather t...   \n",
       "9997  With Istanbul as its capital and control of la...   \n",
       "7476  Economist Simon Kuznets argued that levels of ...   \n",
       "3830  The Apollo program succeeded in achieving its ...   \n",
       "7509  2013 Economics Nobel prize winner Robert J. Sh...   \n",
       "3002  Victoria is the centre of dairy farming in Aus...   \n",
       "5683  One of the earliest surviving examples of Euro...   \n",
       "4798  Fresno is the largest U.S. city not directly l...   \n",
       "7577  Studies on income inequality and growth have s...   \n",
       "\n",
       "                                    baseline_prediction finetuned_prediction  \\\n",
       "7514  conflict, drug use), and lower rates of social...              British   \n",
       "7500                            ., it will also prevent            Economist   \n",
       "9997                                             , thus             Istanbul   \n",
       "7476  . According to Kuznets, countries with low lev...            Economist   \n",
       "3830  . Budget cuts forced the cancellation of three...                 1967   \n",
       "7509                                       , and erodes                 2013   \n",
       "3002  . In 2003â€“04, Victorian commercial fishing cre...             Victoria   \n",
       "5683               , as well as pattern books and paper                 1887   \n",
       "4798  , much discussion has been made to upgrade it ...               Fresno   \n",
       "7577  , which states that with economic development,...            Economist   \n",
       "\n",
       "     ground_truth  baseline_score  finetuned_score  \n",
       "7514      British        0.000105         0.999911  \n",
       "7500    Economist        0.000072         0.999878  \n",
       "9997     Istanbul        0.000153         0.999876  \n",
       "7476    Economist        0.000243         0.999874  \n",
       "3830         1967        0.000129         0.999668  \n",
       "7509         2013        0.000117         0.999642  \n",
       "3002     Victoria        0.000144         0.999574  \n",
       "5683         1887        0.000188         0.999562  \n",
       "4798       Fresno        0.000123         0.999516  \n",
       "7577    Economist        0.000193         0.999464  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"finetuned_score\", ascending=False).head(10) \\\n",
    "    [[\"title\", \"question\", \"context\", \"baseline_prediction\", \"finetuned_prediction\", \"ground_truth\", \"baseline_score\", \"finetuned_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, the analysis can become as long and precise as desired. The best performing answers seem to be related with *Economic_inequality*, although the poor performance of the baseline model doesn't make any particular category stand out since all of them are way better after some fine-tuning.  \n",
    "For instance, let's plot the Levenshtein distance of the baseline model's predictions wrt fine-tuned ones: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"baseline_lev\", \"finetuned_lev\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It stands out that the baseline one is worse for almost every example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The notebook covered this points:\n",
    "* General Question Answering considerations and problem definition.\n",
    "* Model selection: DistilBert as a relatively lightweight model for fine-tuning convenience.\n",
    "* Model fine-tuning: Use of HF Trainer to fine-tune the model, plus HP tuning, TensorBoard logging and monitoring, etc.\n",
    "* Evaluation comparison: Use of HF Evaluate to compare results for both baseline and fine-tuned models, showing that the fine-tuned one clearly outperforms the initial one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* https://huggingface.co/docs/transformers/tasks/question_answering\n",
    "* https://huggingface.co/learn/nlp-course/chapter7/7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
